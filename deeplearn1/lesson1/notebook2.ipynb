{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "require(['base/js/utils'], function(utils) {\n",
    "    utils.load_extensions('usability/ruler/main');\n",
    "    utils.load_extensions('usability/toc2/main');\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Installations 3: Zeppelin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Usage Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll install Zeppelin onto one of our application servers so that we can actually submit jobs to the Ambari cluster. Note that you do not need to use this script if you installed everything via EMR.\n",
    "\n",
    "https://zeppelin.incubator.apache.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from aws_request import *\n",
    "from aws_util import *\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Spot Instance Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instances for the application were generated by the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_request = InstanceRequest('app')\n",
    "app_instances = app_request.get_fulfilled()\n",
    "\n",
    "app_host_names = [instance['PublicDnsName'] for instance in app_instances]\n",
    "app_host_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify SSH User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you created your cluster through EMR, the user is `hadoop`. If you created your cluster as a standard EC2 instance using this notebook series, the user is `ubuntu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_name = 'hadoop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a bucket containing all of our installation files, so your current user will need to have read access to the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bucket_name = 'mdang.lesa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll make sure that our bucket is registered to our application servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_bucket(user_name, app_host_names, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Server Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following decides which host to use for Zeppelin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zeppelin_host_name = app_host_names[-1]\n",
    "\n",
    "print 'Zeppelin', zeppelin_host_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZeppelinHub Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to integrate with ZeppelinHub if you want to preview how your notebook will look using the ZeppelinHub viewer. You can do that by following the instructions below.\n",
    "\n",
    "http://help.zeppelinhub.com/zeppelin_integration/\n",
    "\n",
    "If you're not interested in this integration, leave the `zeppelin_instance_token` at `None`. Otherwise, update the JAR version with whatever version is linked in the above URL and provide the instance token corresponding to your ZeppelinHub instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeppelinhub_jar = 'zeppelinhub-integration-v0.4.0-all.jar'\n",
    "zeppelinhub_api_token = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('zeppelin_hub.sh', 'w') as zeppelin_hub:\n",
    "    print >> zeppelin_hub, 'export ZEPPELINHUB_JAR=' + zeppelinhub_jar\n",
    "    if zeppelinhub_api_token is not None:\n",
    "        print >> zeppelin_hub, 'export ZEPPELINHUB_API_TOKEN=' + zeppelinhub_api_token\n",
    "\n",
    "upload_file(user_name, [zeppelin_host_name], 'zeppelin_hub.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Zeppelin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a script which will install Zeppelin binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile scripts/install_zeppelin.sh\n",
    "#!/bin/bash\n",
    "source ~/.profile\n",
    "\n",
    "ZEPPELIN_VERSION=0.5.6-incubating\n",
    "\n",
    "# Download Zeppelin\n",
    "\n",
    "if [ ! -f zeppelin-$ZEPPELIN_VERSION-bin-all.tgz ]; then\n",
    "    aws s3 cp s3://$S3_BUCKET/zeppelin/zeppelin-$ZEPPELIN_VERSION-bin-all.tgz .\n",
    "    tar -zxf zeppelin-$ZEPPELIN_VERSION-bin-all.tgz\n",
    "fi\n",
    "\n",
    "# Set JAVA_HOME\n",
    "\n",
    "echo \"export JAVA_HOME=$JAVA_HOME\" \\\n",
    "    > zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "chmod u+x zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "# Set memory options\n",
    "\n",
    "echo 'export ZEPPELIN_MEM=\"-Xms2g -Xmx2g\"'\n",
    "    >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "    echo 'export ZEPPELIN_INTP_MEM=\"-Xms2g -Xmx2g\"'\n",
    "    >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "# Enable ZeppelinHub integration\n",
    "\n",
    "source ~/zeppelin_hub.sh\n",
    "\n",
    "if [ ! -f zeppelin-$ZEPPELIN_VERSION-bin-all/lib/$ZEPPELINHUB_JAR ]; then\n",
    "    wget -qq https://s3-ap-northeast-1.amazonaws.com/zeppel.in/$ZEPPELINHUB_JAR\n",
    "    mkdir -p zeppelin-$ZEPPELIN_VERSION-bin-all/lib\n",
    "    mv $ZEPPELINHUB_JAR zeppelin-$ZEPPELIN_VERSION-bin-all/lib\n",
    "fi\n",
    "\n",
    "if [ \"\" != \"$ZEPPELINHUB_API_TOKEN\" ]; then\n",
    "    DEFAULT_REPO=org.apache.zeppelin.notebook.repo.VFSNotebookRepo\n",
    "    ZEPPELINHUB_REPO=com.nflabs.zeppelinhub.notebook.repo.ZeppelinHubRepo\n",
    "\n",
    "    echo \"export ZEPPELIN_NOTEBOOK_STORAGE=\\\"$DEFAULT_REPO, $ZEPPELINHUB_REPO\\\"\" \\\n",
    "        >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "    echo export ZEPPELINHUB_API_ADDRESS=https://www.zeppelinhub.com \\\n",
    "        >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "    echo export ZEPPELINHUB_API_TOKEN=\"$ZEPPELINHUB_API_TOKEN\" \\\n",
    "        >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "fi\n",
    "\n",
    "# Set SPARK_HOME\n",
    "\n",
    "echo \"export SPARK_HOME=$SPARK_HOME\" \\\n",
    "    >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "echo \"export PYSPARK_PYTHON=$(which python)\" \\\n",
    "    >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "echo 'export PY4J_ZIP=$(find -L $SPARK_HOME -name py4j*.zip)' \\\n",
    "    >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "echo 'export SPARK_YARN_USER_ENV=\"PYTHONPATH=$SPARK_HOME/python:$PY4J_ZIP\"' \\\n",
    "    >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "# Set extra options\n",
    "\n",
    "if [ \"\" != \"$(which hdp-select)\" ]; then\n",
    "    export HDP_VERSION=$(hdp-select status hadoop-client | cut -d\" \" -f 3)\n",
    "\n",
    "    echo $HDP_VERSION > hdp_version.txt\n",
    "\n",
    "    echo \"export MASTER=yarn-client\" \\\n",
    "        >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "    echo \"export ZEPPELIN_JAVA_OPTS=-Dhdp.version=$HDP_VERSION\" \\\n",
    "        >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "    echo \"export HADOOP_CONF_DIR=$HADOOP_HOME/conf\" \\\n",
    "        >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "else\n",
    "    cat /dev/null > hdp_version.txt\n",
    "\n",
    "    echo \"export MASTER=local\" \\\n",
    "        >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "\n",
    "    echo \"export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\" \\\n",
    "        >> zeppelin-$ZEPPELIN_VERSION-bin-all/conf/zeppelin-env.sh\n",
    "fi\n",
    "\n",
    "# Start the Zeppelin daemon\n",
    "\n",
    "zeppelin-$ZEPPELIN_VERSION-bin-all/bin/zeppelin-daemon.sh stop\n",
    "zeppelin-$ZEPPELIN_VERSION-bin-all/bin/zeppelin-daemon.sh start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script on all servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_script(user_name, [zeppelin_host_name], 'install_zeppelin.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Notebook GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Zeppelin Server:'\n",
    "print 'http://' + zeppelin_host_name + ':8080/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Spark Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using an Ambari-based installation of Hadoop, there are some additional steps required where you must specify the Hortonworks Data Platform (HDP) version for `spark.driver.extraJavaOptions` and `spark.yarn.am.extraJavaOptions`.\n",
    "\n",
    "The following is the applicable documentation for HDP 2.4 and Zeppelin 0.5.6, which were current as of this writing.\n",
    "\n",
    "* http://hortonworks.com/hadoop-tutorial/apache-zeppelin-hdp-2-4/\n",
    "* https://zeppelin.incubator.apache.org/docs/0.5.6-incubating/install/yarn_install.html\n",
    "\n",
    "You will need the specific HDP version, which can be found by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdp_client_status = subprocess.check_output([\n",
    "    'ssh', '-i', private_key_location,\n",
    "    user_name + '@' + zeppelin_host_name,\n",
    "    'cat hdp_version.txt'\n",
    "]).strip()\n",
    "\n",
    "if len(hdp_client_status) > 0:\n",
    "    print 'spark.driver.extraJavaOptions\\t-Dhdp.version=' + hdp_client_status\n",
    "    print 'spark.yarn.am.extraJavaOptions\\t-Dhdp.version=' + hdp_client_status\n",
    "else:\n",
    "    print 'Not using Hortonworks Data Platform'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:legacy]",
   "language": "python",
   "name": "conda-env-legacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}